{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1. Import thư viện"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:23:58.495030Z","iopub.status.busy":"2024-09-25T12:23:58.494308Z","iopub.status.idle":"2024-09-25T12:24:03.729522Z","shell.execute_reply":"2024-09-25T12:24:03.728566Z","shell.execute_reply.started":"2024-09-25T12:23:58.494992Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms\n","from torchsummary import summary\n","from torch.utils.data import DataLoader, Dataset\n","import cv2\n","import numpy as np\n","import os\n","from PIL import Image\n","from tqdm import tqdm\n","import time\n","import matplotlib.pyplot as plt\n","from models.hqsr import *"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.731452Z","iopub.status.busy":"2024-09-25T12:24:03.730941Z","iopub.status.idle":"2024-09-25T12:24:03.794823Z","shell.execute_reply":"2024-09-25T12:24:03.793839Z","shell.execute_reply.started":"2024-09-25T12:24:03.731417Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Tạo Mô hình SR"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.824325Z","iopub.status.busy":"2024-09-25T12:24:03.823331Z","iopub.status.idle":"2024-09-25T12:24:03.833160Z","shell.execute_reply":"2024-09-25T12:24:03.832215Z","shell.execute_reply.started":"2024-09-25T12:24:03.824292Z"},"trusted":true},"outputs":[],"source":["class ImageDataset(Dataset):\n","    def __init__(self, lr_dir, hr_dir, scale, valid = False):\n","        self.lr_files = sorted(os.listdir(lr_dir))\n","        self.hr_files = sorted(os.listdir(hr_dir))\n","        self.lr_dir = lr_dir\n","        self.hr_dir = hr_dir\n","        self.scale = scale\n","        self.valid = valid\n","\n","    def __len__(self):\n","        return len(self.lr_files)\n","\n","    def __getitem__(self, idx):\n","        lr_image = Image.open(os.path.join(self.lr_dir, self.lr_files[idx])).convert('RGB')\n","        hr_image = Image.open(os.path.join(self.hr_dir, self.hr_files[idx])).convert('RGB')\n","    \n","        w, h= hr_image.size\n","        if self.valid:\n","            lr_image = lr_image.resize((w//self.scale, h//self.scale))\n","        transform = transforms.Compose([\n","            transforms.ToTensor()\n","        ])\n","        \n","        lr_image = transform(lr_image)\n","        hr_image = transform(hr_image)\n","        return lr_image, hr_image"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Tạo Hyperparameter"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.835254Z","iopub.status.busy":"2024-09-25T12:24:03.834750Z","iopub.status.idle":"2024-09-25T12:24:03.841602Z","shell.execute_reply":"2024-09-25T12:24:03.840600Z","shell.execute_reply.started":"2024-09-25T12:24:03.835180Z"},"trusted":true},"outputs":[],"source":["# Đường dẫn tới bộ dữ liệu\n","\n","# test_hr_dir  = '/kaggle/input/srdataset/sr_data/test/HR'\n","# test_lr_dir  = '/kaggle/input/srdataset/sr_data/test/LR'\n","\n","# print(torch.cuda.memory_allocated())\n","# print(torch.cuda.memory_reserved())"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["import os\n","os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n","os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\""]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["def calculate_psnr(img1, img2):\n","    mse = torch.mean((img1 - img2) ** 2)\n","    if mse == 0:\n","        return float('inf')\n","    max_pixel = 1.0\n","    psnr = 20 * torch.log10(max_pixel / torch.sqrt(mse))\n","    return psnr.item()"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Training"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:33:32.155872Z","iopub.status.busy":"2024-09-25T12:33:32.154884Z","iopub.status.idle":"2024-09-25T14:57:54.133761Z","shell.execute_reply":"2024-09-25T14:57:54.132406Z","shell.execute_reply.started":"2024-09-25T12:33:32.155839Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|▏         | 170/12500 [00:16<19:53, 10.33batch/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m     loss_sobel \u001b[38;5;241m=\u001b[39m criterion(outputs_sobel, hr_images)\n\u001b[1;32m     72\u001b[0m psnr_sobel \u001b[38;5;241m=\u001b[39m calculate_psnr(outputs_sobel, hr_images)\n\u001b[0;32m---> 74\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_sobel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optim_sobel)\n\u001b[1;32m     76\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from torch.amp import autocast, GradScaler\n","from torchsummary import summary\n","scaler = GradScaler()\n","\n","# Khởi tạo dataset và dataloader\n","for scale in [2, 3, 4]:\n","    train_lr_dir = f'dataset/Train/LR_{scale}'\n","    train_hr_dir = 'dataset/Train/HR'\n","    valid_lr_dir = 'dataset/Test/HR'\n","    valid_hr_dir = 'dataset/Test/HR'\n","    train_dataset = ImageDataset(train_lr_dir, train_hr_dir, scale=scale)\n","    train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True)\n","\n","    valid_dataset = ImageDataset(valid_lr_dir, valid_hr_dir, scale=scale, valid=True)\n","    valid_loader = DataLoader(valid_dataset)\n","\n","    # print(len(train_loader))\n","    # Khởi tạo mô hình, loss function và optimizer\n","    torch.cuda.empty_cache()\n","\n","    sobelsr = HQSR(scale_factor = scale, use_sobel = True).to(device)\n","    # sobelsr.load_state_dict(torch.load('weight/best_sobel_srx4_model.pth', map_location=device))\n","    criterion = nn.MSELoss()\n","    optim_sobel = optim.Adam(sobelsr.parameters(), lr=1e-4,betas =(0.9, 0.999))\n","    scheduler_sobel = optim.lr_scheduler.StepLR(optim_sobel, step_size=10**5, gamma=0.5)\n","    # summary(sobelsr.cuda(), input_size=(3, 510, 339), device='cuda')\n","    cannysr = HQSR(scale_factor = scale, use_canny = True).to(device)\n","    # cannysr = nn.DataParallel(cannysr).to(device)\n","    # cannysr.load_state_dict(torch.load('weight/best_canny_srx4_model.pth', map_location=device))\n","    \n","    optim_canny = optim.Adam(cannysr.parameters(), lr=1e-4,betas =(0.9, 0.999))\n","    scheduler_canny = optim.lr_scheduler.StepLR(optim_canny, step_size=10**5, gamma=0.5)\n","    num_epochs = 24\n","\n","    best_psnr_sobel = float('-inf')\n","    best_psnr_canny = float('-inf')\n","    torch.cuda.empty_cache()\n","\n","    losses_sobel = []\n","    losses_canny = []\n","    avg_psnr_sobel = []\n","    avg_psnr_canny = []\n","\n","    val_avg_psnr_sobel = []  # Validation PSNR\n","    val_avg_psnr_canny = []\n","\n","    patience = 5\n","    epochs_no_improve = 0\n","    log_file = open('outputs/train_log/hqsr.txt', 'a')\n","    scaler = GradScaler()\n","\n","    for epoch in range(num_epochs):\n","        sobelsr.train()\n","        cannysr.train()\n","\n","        epoch_loss_sobel = 0\n","        psnr_values_sobel = 0\n","        epoch_loss_canny = 0\n","        psnr_values_canny = 0\n","        start_time = time.time()\n","\n","        # Training loop\n","        for (lr_images, hr_images) in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch'):\n","            lr_images = lr_images.cuda()\n","            hr_images = hr_images.cuda()\n","\n","            # Sobel SR training\n","            optim_sobel.zero_grad()  \n","            with autocast(device_type='cuda'):\n","                outputs_sobel = sobelsr(lr_images)\n","                loss_sobel = criterion(outputs_sobel, hr_images)\n","            psnr_sobel = calculate_psnr(outputs_sobel, hr_images)\n","                \n","            scaler.scale(loss_sobel).backward()\n","            scaler.step(optim_sobel)\n","            scaler.update()\n","            scheduler_sobel.step()\n","\n","            # Canny SR training\n","            optim_canny.zero_grad()  \n","            with autocast(device_type='cuda'):\n","                outputs_canny = cannysr(lr_images)\n","                loss_canny = criterion(outputs_canny, hr_images)\n","            psnr_canny = calculate_psnr(outputs_canny, hr_images)\n","\n","            scaler.scale(loss_canny).backward()\n","            scaler.step(optim_canny)\n","            scaler.update()\n","            scheduler_canny.step()\n","            \n","            # Update metrics\n","            epoch_loss_sobel += loss_sobel.item()\n","            psnr_values_sobel += psnr_sobel\n","            epoch_loss_canny += loss_canny.item()\n","            psnr_values_canny += psnr_canny\n","\n","        # Calculate average training metrics\n","        avg_epoch_loss_sobel = epoch_loss_sobel / len(train_loader)\n","        average_psnr_sobel = psnr_values_sobel / len(train_loader)\n","        losses_sobel.append(avg_epoch_loss_sobel)\n","        avg_psnr_sobel.append(average_psnr_sobel)\n","\n","        avg_epoch_loss_canny = epoch_loss_canny / len(train_loader)\n","        average_psnr_canny = psnr_values_canny / len(train_loader)\n","        losses_canny.append(avg_epoch_loss_canny)\n","        avg_psnr_canny.append(average_psnr_canny)\n","\n","        # Validation step\n","        sobelsr.eval()\n","        cannysr.eval()\n","\n","        val_psnr_values_sobel = 0\n","        val_psnr_values_canny = 0\n","\n","        with torch.no_grad():  # No gradients during validation\n","            for (lr_images, hr_images) in tqdm(valid_loader, desc=f'Validation Epoch {epoch+1}/{num_epochs}', unit='batch'):\n","                lr_images = lr_images.cuda()\n","                hr_images = hr_images.cuda()\n","\n","                # Sobel SR validation (no loss, only PSNR)\n","                outputs_sobel = sobelsr(lr_images)\n","                psnr_sobel = calculate_psnr(outputs_sobel, hr_images)\n","\n","                # Canny SR validation (no loss, only PSNR)\n","                outputs_canny = cannysr(lr_images)\n","                psnr_canny = calculate_psnr(outputs_canny, hr_images)\n","\n","                # Update validation PSNR\n","                val_psnr_values_sobel += psnr_sobel\n","                val_psnr_values_canny += psnr_canny\n","\n","        # Calculate average validation PSNR\n","        val_average_psnr_sobel = val_psnr_values_sobel / len(valid_loader)\n","        val_avg_psnr_sobel.append(val_average_psnr_sobel)\n","\n","        val_average_psnr_canny = val_psnr_values_canny / len(valid_loader)\n","        val_avg_psnr_canny.append(val_average_psnr_canny)\n","\n","        end_time = time.time()\n","\n","        # Logging results\n","        log_string = (f\"Epoch {epoch+1}/{num_epochs}, Loss sobel: {avg_epoch_loss_sobel:.4f}, \"\n","                    f\"Loss canny: {avg_epoch_loss_canny:.4f}, Time training: {end_time - start_time:.4f}s, \"\n","                    f\"PSNR sobel: {average_psnr_sobel:.2f} dB, PSNR canny: {average_psnr_canny:.2f} dB, \"\n","                    f\"Val PSNR sobel: {val_average_psnr_sobel:.2f} dB, Val PSNR canny: {val_average_psnr_canny:.2f} dB\")\n","        print(log_string)\n","        log_file.write(log_string + '\\n')\n","        log_file.flush()\n","\n","        # Save best models based on validation PSNR\n","        if val_average_psnr_sobel > best_psnr_sobel:\n","            best_psnr_sobel = val_average_psnr_sobel\n","            torch.save(sobelsr.state_dict(), f'outputs/weight_sr/x{scale}/best_hqsr_sobel.pth')\n","            print(f\"Saved Sobel SR model with PSNR {best_psnr_sobel:.4f}\")\n","            epochs_no_improve=0\n","        \n","\n","        if val_average_psnr_canny > best_psnr_canny:\n","            best_psnr_canny = val_average_psnr_canny\n","            torch.save(cannysr.state_dict(), f'outputs/weight_sr/x{scale}/best_hqsr_canny.pth')\n","            print(f\"Saved Canny SR model with PSNR {best_psnr_canny:.4f}\")\n","            epochs_no_improve=0\n","        \n","        if (val_average_psnr_sobel < best_psnr_sobel) and (val_average_psnr_canny < best_psnr_canny):\n","            epochs_no_improve+=1\n","        if epochs_no_improve >= patience:\n","            print(f\"PSNR did not improve for 50 epochs. Early stopping at epoch {epoch+1}\")\n","            break\n","        # Clear cache and optionally save models at each epoch\n","        save_dir = f'outputs/path/x{scale}'\n","        if not os.path.exists(save_dir):\n","            os.makedirs(save_dir)\n","\n","        torch.save(sobelsr.state_dict(), os.path.join(save_dir, f'hqsr_sobel_{epoch}.pth'))\n","        torch.save(cannysr.state_dict(), os.path.join(save_dir, f'hqsr_canny_{epoch}.pth'))\n","            # Close log file after training\n","    log_file.close()\n","\n","    # Plotting results\n","    plt.figure(figsize=(12, 10))\n","\n","    # Plot loss\n","    plt.subplot(2, 1, 1)\n","    plt.plot(losses_sobel, label='Sobel SR Loss (Train)')\n","    plt.plot(losses_canny, label='Canny SR Loss (Train)')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.title('Training Loss')\n","\n","    # Plot PSNR\n","    plt.subplot(2, 1, 2)\n","    plt.plot(avg_psnr_sobel, label='Sobel SR PSNR (Train)')\n","    plt.plot(val_avg_psnr_sobel, label='Sobel SR PSNR (Val)')\n","    plt.plot(avg_psnr_canny, label='Canny SR PSNR (Train)')\n","    plt.plot(val_avg_psnr_canny, label='Canny SR PSNR (Val)')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('PSNR (dB)')\n","    plt.legend()\n","    plt.title('Average PSNR (Train and Val)')\n","\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-25T12:24:11.229549Z","iopub.status.idle":"2024-09-25T12:24:11.229851Z","shell.execute_reply":"2024-09-25T12:24:11.229713Z","shell.execute_reply.started":"2024-09-25T12:24:11.229700Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Validation Epoch 100/100: 100%|██████████| 1068/1068 [00:29<00:00, 36.72batch/s]"]},{"name":"stdout","output_type":"stream","text":["34.99811347325643 34.955485554670126\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["cannysr = cannysr.cpu()\n","sobelsr = sobelsr.cpu()\n","sobelsr.eval()\n","cannysr.eval()\n","\n","val_psnr_values_sobel = 0\n","val_psnr_values_canny = 0\n","torch.cuda.empty_cache()\n","with torch.no_grad():  # No gradients during validation\n","        for (lr_images, hr_images) in tqdm(valid_loader, desc=f'Validation Epoch {epoch+1}/{num_epochs}', unit='batch'):\n","                lr_images = lr_images.cpu()\n","                hr_images = hr_images.cpu()\n","\n","                # Sobel SR validation (no loss, only PSNR)\n","                outputs_sobel = sobelsr(lr_images)\n","                psnr_sobel = calculate_psnr(outputs_sobel, hr_images)\n","\n","                # Canny SR validation (no loss, only PSNR)\n","                outputs_canny = cannysr(lr_images)\n","                psnr_canny = calculate_psnr(outputs_canny, hr_images)\n","\n","                # Update validation PSNR\n","                val_psnr_values_sobel += psnr_sobel\n","                val_psnr_values_canny += psnr_canny\n","\n","        # Calculate average validation PSNR\n","        val_average_psnr_sobel = val_psnr_values_sobel / len(valid_loader)\n","\n","        val_average_psnr_canny = val_psnr_values_canny / len(valid_loader)\n","        print(val_average_psnr_canny, val_average_psnr_sobel)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Validation Epoch 100/100: 100%|██████████| 1068/1068 [00:29<00:00, 36.72batch/s]"]},{"name":"stdout","output_type":"stream","text":["34.99811347325643 34.955485554670126\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["cannysr = cannysr.cpu()\n","sobelsr = sobelsr.cpu()\n","sobelsr.eval()\n","cannysr.eval()\n","\n","val_psnr_values_sobel = 0\n","val_psnr_values_canny = 0\n","torch.cuda.empty_cache()\n","with torch.no_grad():  # No gradients during validation\n","        for (lr_images, hr_images) in tqdm(valid_loader, desc=f'Validation Epoch {epoch+1}/{num_epochs}', unit='batch'):\n","                lr_images = lr_images.cpu()\n","                hr_images = hr_images.cpu()\n","\n","                # Sobel SR validation (no loss, only PSNR)\n","                outputs_sobel = sobelsr(lr_images)\n","                psnr_sobel = calculate_psnr(outputs_sobel, hr_images)\n","\n","                # Canny SR validation (no loss, only PSNR)\n","                outputs_canny = cannysr(lr_images)\n","                psnr_canny = calculate_psnr(outputs_canny, hr_images)\n","\n","                # Update validation PSNR\n","                val_psnr_values_sobel += psnr_sobel\n","                val_psnr_values_canny += psnr_canny\n","\n","        # Calculate average validation PSNR\n","        val_average_psnr_sobel = val_psnr_values_sobel / len(valid_loader)\n","\n","        val_average_psnr_canny = val_psnr_values_canny / len(valid_loader)\n","        print(val_average_psnr_canny, val_average_psnr_sobel)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5414450,"sourceId":8989742,"sourceType":"datasetVersion"},{"datasetId":5671931,"sourceId":9356096,"sourceType":"datasetVersion"},{"datasetId":5764801,"sourceId":9478075,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
