{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1. Import thư viện"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:23:58.495030Z","iopub.status.busy":"2024-09-25T12:23:58.494308Z","iopub.status.idle":"2024-09-25T12:24:03.729522Z","shell.execute_reply":"2024-09-25T12:24:03.728566Z","shell.execute_reply.started":"2024-09-25T12:23:58.494992Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import numpy as np\n","import os\n","from PIL import Image\n","import shutil\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset\n","from torch.nn.parallel import DataParallel\n","from torch.cuda.amp import autocast, GradScaler\n","import torch.nn.functional as F\n","from torchvision.utils import save_image\n","\n","from tqdm import tqdm\n","from models.vdsr import *\n","from models.srcnn import *\n","import time\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.731452Z","iopub.status.busy":"2024-09-25T12:24:03.730941Z","iopub.status.idle":"2024-09-25T12:24:03.794823Z","shell.execute_reply":"2024-09-25T12:24:03.793839Z","shell.execute_reply.started":"2024-09-25T12:24:03.731417Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n","os.environ['PYTORCH_CUDA_ALLOC_CONF']='expandable_segments:True'\n","os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Tạo Mô hình SR"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.797602Z","iopub.status.busy":"2024-09-25T12:24:03.797285Z","iopub.status.idle":"2024-09-25T12:24:03.821933Z","shell.execute_reply":"2024-09-25T12:24:03.821064Z","shell.execute_reply.started":"2024-09-25T12:24:03.797577Z"},"trusted":true},"outputs":[],"source":["\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.824325Z","iopub.status.busy":"2024-09-25T12:24:03.823331Z","iopub.status.idle":"2024-09-25T12:24:03.833160Z","shell.execute_reply":"2024-09-25T12:24:03.832215Z","shell.execute_reply.started":"2024-09-25T12:24:03.824292Z"},"trusted":true},"outputs":[],"source":["class ImageDataset(Dataset):\n","    def __init__(self, lr_dir, hr_dir, valid = False, scale=4, vdsr = False):\n","        self.lr_files = sorted(os.listdir(lr_dir))\n","        self.hr_files = sorted(os.listdir(hr_dir))\n","        self.lr_dir = lr_dir\n","        self.hr_dir = hr_dir\n","        self.valid = valid\n","        self.scale = scale\n","        self.vdsr = vdsr\n","    def __len__(self):\n","        return len(self.lr_files)\n","\n","    def __getitem__(self, idx):\n","        lr_image = Image.open(os.path.join(self.lr_dir, self.lr_files[idx])).convert('RGB')\n","        hr_image = Image.open(os.path.join(self.hr_dir, self.hr_files[idx])).convert('RGB')\n","        \n","        w, h = hr_image.size\n","  \n","        if self.valid:\n","            lr_image = lr_image.resize((w//self.scale, h//self.scale))\n","        if self.vdsr:\n","            lr_image = lr_image.resize((w, h))\n","        transform = transforms.Compose([\n","            # transforms.ToPILImage(),\n","            transforms.ToTensor()\n","        ])\n","        \n","        lr_image = transform(lr_image)\n","        hr_image = transform(hr_image)\n","        return lr_image, hr_image"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Tạo Hyperparameter"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:33:29.152867Z","iopub.status.busy":"2024-09-25T12:33:29.152523Z","iopub.status.idle":"2024-09-25T12:33:30.352211Z","shell.execute_reply":"2024-09-25T12:33:30.351285Z","shell.execute_reply.started":"2024-09-25T12:33:29.152842Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["12500\n"]}],"source":["from torch.amp import autocast, GradScaler\n","scaler = GradScaler()\n","\n","# Khởi tạo dataset và dataloader\n","for scale in [2, 3, 4]:\n","    train_lr_dir = f'dataset/Train/LR_{scale}'\n","    train_hr_dir = 'dataset/Train/HR'\n","    valid_lr_dir = 'dataset/Test/HR'\n","    valid_hr_dir = 'dataset/Test/HR'\n","    vdsr = VDSR().to(device)\n","    srcnn = SRCNN().to(device)\n","    train_dataset = ImageDataset(train_lr_dir, train_hr_dir,scale, vdsr=True)\n","    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","\n","    valid_dataset = ImageDataset(valid_lr_dir, valid_hr_dir, valid=True, scale=scale,vdsr=True)\n","    valid_loader = DataLoader(valid_dataset)\n","\n","    # Khởi tạo loss function\n","    criterion = nn.MSELoss()\n","    \n","    optim_srcnn = optim.Adam(srcnn.parameters(), lr=1e-5, betas=(0.9, 0.999))\n","    scheduler_srcnn = optim.lr_scheduler.StepLR(optim_srcnn, step_size=10**5, gamma=0.5)\n","\n","    optim_vdsr = optim.Adam(vdsr.parameters(), lr=1e-4, betas=(0.9, 0.999))\n","    scheduler_vdsr = optim.lr_scheduler.StepLR(optim_vdsr, step_size=10**5, gamma=0.5)\n","    # Hàm tính PSNR\n","    def calculate_psnr(img1, img2):\n","        mse = torch.mean((img1 - img2) ** 2)\n","        if mse == 0:\n","            return float('inf')\n","        max_pixel = 1.0\n","        psnr = 20 * torch.log10(max_pixel / torch.sqrt(mse))\n","        return psnr.item()\n","\n","    num_epochs = 24\n","\n","    best_psnr_srcnn = float('-inf')\n","    best_psnr_vdsr = float('-inf')\n","    torch.cuda.empty_cache()\n","\n","    losses_srcnn = []\n","    losses_vdsr = []\n","\n","    avg_psnr_srcnn = []\n","    avg_psnr_vdsr = []\n","\n","    val_avg_psnr_srcnn = []\n","    val_avg_psnr_vdsr = []\n","\n","    patience = 5\n","    epochs_no_improve = 0\n","    log_file = open('outputs/train_log/srcnnn_vdsr.txt', 'a')\n","\n","    for epoch in range(num_epochs):\n","        srcnn.train()\n","        vdsr.train()\n","\n","        epoch_loss_srcnn, psnr_values_srcnn = 0, 0\n","        epoch_loss_vdsr, psnr_values_vdsr = 0, 0\n","        start_time = time.time()\n","\n","        # Training loop for srcnn\n","        for (lr_images, hr_images) in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch'):\n","            lr_images = lr_images.cuda()\n","            hr_images = hr_images.cuda()\n","\n","            # Train srcnn model\n","            optim_srcnn.zero_grad()\n","            with autocast(device_type='cuda'):\n","                outputs_srcnn =srcnn(lr_images)\n","                loss_srcnn = criterion(outputs_srcnn, hr_images)\n","            psnr_srcnn = calculate_psnr(outputs_srcnn, hr_images)\n","            # if psnr_srcnn < 27:\n","            scaler.scale(loss_srcnn).backward()\n","            scaler.step(optim_srcnn)\n","            scaler.update()\n","            scheduler_srcnn.step()\n","\n","            epoch_loss_srcnn += loss_srcnn.item()\n","            psnr_values_srcnn += psnr_srcnn\n","\n","            optim_vdsr.zero_grad()\n","            with autocast(device_type='cuda'):\n","                outputs_vdsr = vdsr(lr_images)\n","                loss_vdsr = criterion(outputs_vdsr, hr_images)\n","            psnr_vdsr = calculate_psnr(outputs_vdsr, hr_images)\n","\n","            scaler.scale(loss_vdsr).backward()\n","            scaler.step(optim_vdsr)\n","            scaler.update()\n","            scheduler_vdsr.step()\n","\n","            epoch_loss_vdsr += loss_vdsr.item()\n","            psnr_values_vdsr += psnr_vdsr\n","        \n","        # Training loop for vdsr\n","    \n","            \n","        # Average losses and PSNRs\n","        avg_epoch_loss_srcnn = epoch_loss_srcnn / len(train_loader)\n","        avg_psnr_srcnn_epoch = psnr_values_srcnn / len(train_loader)\n","        losses_srcnn.append(avg_epoch_loss_srcnn)\n","        avg_psnr_srcnn.append(avg_psnr_srcnn_epoch)\n","\n","        avg_epoch_loss_vdsr = epoch_loss_vdsr / len(train_loader)\n","        avg_psnr_vdsr_epoch = psnr_values_vdsr / len(train_loader)\n","        losses_vdsr.append(avg_epoch_loss_vdsr)\n","        avg_psnr_vdsr.append(avg_psnr_vdsr_epoch)\n","\n","        # Validation for srcnn and vdsr\n","        srcnn.eval()\n","        vdsr.eval()\n","\n","        val_psnr_srcnn, val_psnr_vdsr = 0, 0\n","\n","        with torch.no_grad():\n","            # Validate srcnn\n","            for (lr_images, hr_images) in valid_loader:\n","                lr_images = lr_images.cuda()\n","                hr_images = hr_images.cuda()\n","\n","                outputs_srcnn = srcnn(lr_images)\n","                psnr_srcnn = calculate_psnr(outputs_srcnn, hr_images)\n","                val_psnr_srcnn += psnr_srcnn\n","\n","\n","                outputs_vdsr = vdsr(lr_images)\n","                psnr_vdsr = calculate_psnr(outputs_vdsr, hr_images)\n","                val_psnr_vdsr += psnr_vdsr\n","            # Validate vdsr\n","            \n","\n","\n","        val_avg_psnr_srcnn_epoch = val_psnr_srcnn / len(valid_loader)\n","        val_avg_psnr_srcnn.append(val_avg_psnr_srcnn_epoch)\n","\n","        val_avg_psnr_vdsr_epoch = val_psnr_vdsr / len(valid_loader)\n","        val_avg_psnr_vdsr.append(val_avg_psnr_vdsr_epoch)\n","\n","        # Save best model for srcnn\n","        if val_avg_psnr_srcnn_epoch > best_psnr_srcnn:\n","            best_psnr_srcnn = val_avg_psnr_srcnn_epoch\n","            torch.save(srcnn.state_dict(), f'outputs/weight_sr/x{scale}/best_srcnn.pth')\n","            print(f\"Saved SRCNN model with PSNR {best_psnr_srcnn:.4f}\")\n","        # Save best model for vdsr\n","        if val_avg_psnr_vdsr_epoch > best_psnr_vdsr:\n","            best_psnr_vdsr = val_avg_psnr_vdsr_epoch\n","            torch.save(vdsr.state_dict(), f'outputs/weight_sr/x{scale}/best_vdsr.pth')\n","            print(f\"Saved VDSR model with PSNR {best_psnr_vdsr:.4f}\")\n","\n","        torch.save(srcnn.state_dict(), f'outputs/path/srcnn_{epoch+10}.pth')\n","        torch.save(vdsr.state_dict(), f'outputs/path/vdsr_{epoch+10}.pth')\n","        print(f\"Epoch [{epoch+1}/{num_epochs}] completed: srcnn Loss: {avg_epoch_loss_srcnn:.4f}, PSNR: {avg_psnr_srcnn_epoch:.4f}, Validation PSNR: {val_avg_psnr_srcnn_epoch:.4f}\")\n","        print(f\"Epoch [{epoch+1}/{num_epochs}] completed: vdsr Loss: {avg_epoch_loss_vdsr:.4f}, PSNR: {avg_psnr_vdsr_epoch:.4f}, Validation PSNR: {val_avg_psnr_vdsr_epoch:.4f}\")\n","\n","        log_file.write(f\"Epoch {epoch+1}: WDSRA PSNR: {avg_psnr_srcnn_epoch:.4f}, Validation PSNR: {val_avg_psnr_srcnn_epoch:.4f}\\n\")\n","        log_file.write(f\"Epoch {epoch+1}: vdsr PSNR: {avg_psnr_vdsr_epoch:.4f}, Validation PSNR: {val_avg_psnr_vdsr_epoch:.4f}\\n\")\n","\n","        # log_file.flush()\n","\n","    log_file.close()\n"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Training"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5414450,"sourceId":8989742,"sourceType":"datasetVersion"},{"datasetId":5671931,"sourceId":9356096,"sourceType":"datasetVersion"},{"datasetId":5764801,"sourceId":9478075,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
